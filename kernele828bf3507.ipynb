{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from pandas import DataFrame\n",
    "import re\n",
    "import os\n",
    "data= pd.read_csv('../input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "data.loc[data['target']<0.48, 'target']=0\n",
    "data.loc[data['target']>=0.48, 'target']=1\n",
    "data['target']= data['target'].round(decimals=0)\n",
    "x= data['comment_text']\n",
    "targets= data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.pooling import GlobalMaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GRU, Embedding, Dropout, MaxPooling1D, Conv1D, AveragePooling1D, Flatten,Bidirectional,BatchNormalization, LSTM, SpatialDropout1D\n",
    "from keras.initializers import TruncatedNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_lengthening(text):\n",
    "\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return pattern.sub(r\"\\1\\1\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer( filters='!\"#$%&()*+,-./:;<=>@[\\\\]^_`{|}~\\t\\n', lower=True)\n",
    "test_data= pd.read_csv('../input/test.csv')\n",
    "\n",
    "x=[reduce_lengthening(i) for i in x]\n",
    "tokenizer.fit_on_texts(x)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, x_test, y_train, y_test= tts(x,targets,test_size=0.2, random_state=4)\n",
    "x_tr=tokenizer.texts_to_sequences(x_train)\n",
    "x_ts=tokenizer.texts_to_sequences(x_test)\n",
    "x_tr=pad_sequences(x_tr, maxlen=250)\n",
    "x_ts=pad_sequences(x_ts, maxlen=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 250, 20)           8782120   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 125, 20)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 62, 20)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 256)               212736    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               77100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 9,072,257\n",
      "Trainable params: 9,072,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 20\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim= embedding_dim, input_length=250, embeddings_initializer='TruncatedNormal'))\n",
    "#model.add(SpatialDropout1D(0.2))\n",
    "model.add(AveragePooling1D(pool_size=2))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add((GRU(256, recurrent_dropout=0.2)))\n",
    "#model.add(Conv1D(100, kernel_size=8, activation='relu'))\n",
    "#model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/3\n",
      "1443899/1443899 [==============================] - 400s 277us/step - loss: 0.1834 - acc: 0.9379\n",
      "Epoch 2/3\n",
      " 195300/1443899 [===>..........................] - ETA: 5:44 - loss: 0.1502 - acc: 0.9454"
     ]
    }
   ],
   "source": [
    "model.fit(x_tr, y_train,epochs=3,verbose=1,batch_size=300)\n",
    "_, val_acc1 = model.evaluate(x_ts, y_test, verbose=0)\n",
    "print('val_acc is: ', val_acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 250, 50)           21955300  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 241, 200)          100200    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 121, 200)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 25, 200)           0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 256)               350976    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 22,406,733\n",
      "Trainable params: 22,406,733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 50\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(input_dim=vocab_size, output_dim= embedding_dim, input_length=250, embeddings_initializer='TruncatedNormal'))\n",
    "model2.add(Conv1D(200, kernel_size=10,strides=1,activation='relu' ))\n",
    "model2.add(AveragePooling1D(pool_size=2, strides=None, padding='same'))\n",
    "model2.add(MaxPooling1D(pool_size=5, strides=None, padding='same'))\n",
    "model2.add(GRU(256, recurrent_dropout=0.2))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test= tts(x,targets,test_size=0.2, random_state=12)\n",
    "x_tr=tokenizer.texts_to_sequences(x_train)\n",
    "x_ts=tokenizer.texts_to_sequences(x_test)\n",
    "x_tr=pad_sequences(x_tr, maxlen=250)\n",
    "x_ts=pad_sequences(x_ts, maxlen=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1443899/1443899 [==============================] - 260s 180us/step - loss: 0.1410 - acc: 0.9474\n",
      "Epoch 2/2\n",
      "1443899/1443899 [==============================] - 256s 177us/step - loss: 0.1098 - acc: 0.9561\n",
      "val_acc is:  0.9475337627262808\n"
     ]
    }
   ],
   "source": [
    "model2.fit(x_tr, y_train,epochs=2,verbose=1,batch_size=300)\n",
    "_, val_acc2 = model2.evaluate(x_ts, y_test, verbose=0)\n",
    "print('val_acc is: ', val_acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 250, 30)           13173180  \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 241, 200)          60200     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3 (Average (None, 121, 200)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 25, 200)           0         \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 256)               350976    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 13,584,613\n",
      "Trainable params: 13,584,613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 30\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(input_dim=vocab_size, output_dim= embedding_dim, input_length=250, embeddings_initializer='TruncatedNormal'))\n",
    "model3.add(Conv1D(200, kernel_size=10,strides=1,activation='relu' ))\n",
    "model3.add(AveragePooling1D(pool_size=2, strides=None, padding='same'))\n",
    "model3.add(MaxPooling1D(pool_size=5, strides=None, padding='same'))\n",
    "model3.add(GRU(256, recurrent_dropout=0.2))\n",
    "model3.add(Dropout(0.3))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "model3.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test= tts(x,targets,test_size=0.25, random_state=24)\n",
    "x_tr=tokenizer.texts_to_sequences(x_train)\n",
    "x_ts=tokenizer.texts_to_sequences(x_test)\n",
    "x_tr=pad_sequences(x_tr, maxlen=250, padding='post', truncating='post')\n",
    "x_ts=pad_sequences(x_ts, maxlen=250, padding='post', truncating='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1353655/1353655 [==============================] - 210s 155us/step - loss: 0.1484 - acc: 0.9457\n",
      "Epoch 2/2\n",
      "1353655/1353655 [==============================] - 209s 154us/step - loss: 0.1133 - acc: 0.9548\n",
      "val_acc is:  0.9505317816856498\n"
     ]
    }
   ],
   "source": [
    "model3.fit(x_tr, y_train,epochs=2,verbose=1,batch_size=300)\n",
    "_, val_acc3 = model3.evaluate(x_ts, y_test, verbose=0)\n",
    "print('val_acc is: ', val_acc3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 250, 20)           8782120   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 241, 200)          40200     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 121, 200)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 25, 200)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               467968    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 9,290,545\n",
      "Trainable params: 9,290,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "embedding_dim = 20\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(Embedding(input_dim=vocab_size, output_dim= embedding_dim, input_length=250, embeddings_initializer='TruncatedNormal'))\n",
    "model4.add(Conv1D(200, kernel_size=10,strides=1 ))\n",
    "model4.add(AveragePooling1D(pool_size=2, strides=None, padding='same'))\n",
    "model4.add(MaxPooling1D(pool_size=5, strides=None, padding='same'))\n",
    "model4.add(LSTM(256, recurrent_dropout=0.2))\n",
    "model4.add(Dropout(0.3))\n",
    "model4.add(Dense(1, activation='sigmoid'))\n",
    "model4.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test= tts(x,targets,test_size=0.15, random_state=122)\n",
    "x_tr=tokenizer.texts_to_sequences(x_train)\n",
    "x_ts=tokenizer.texts_to_sequences(x_test)\n",
    "x_tr=pad_sequences(x_tr, maxlen=250, padding='post', truncating='post')\n",
    "x_ts=pad_sequences(x_ts, maxlen=250, padding='post', truncating='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1534142/1534142 [==============================] - 254s 166us/step - loss: 0.2436 - acc: 0.9263\n",
      "Epoch 2/2\n",
      "1534142/1534142 [==============================] - 252s 164us/step - loss: 0.1276 - acc: 0.9506\n",
      "val_acc is:  0.949470324896946\n"
     ]
    }
   ],
   "source": [
    "model4.fit(x_tr, y_train,epochs=2,verbose=1,batch_size=300)\n",
    "_, val_acc4 = model4.evaluate(x_ts, y_test, verbose=0)\n",
    "print('val_acc is: ', val_acc4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', decode_error='ignore')\n",
    "#x_train= vectorizer.fit_transform(x_train.values)\n",
    "clf =  LogisticRegression()\n",
    "clf.fit(x_tr, y_train)\n",
    "#x_test=vectorizer.transform(x_test)\n",
    "pred = clf.predict(x_ts)\n",
    "val_acc5 = metrics.accuracy_score(y_test, pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "coef1=0.892\n",
    "coef2=0.895\n",
    "coef3=0.897\n",
    "coef4=0.895\n",
    "coef5=0.75\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test=test_data['comment_text']\n",
    "test=[reduce_lengthening(i) for i in test]\n",
    "#testx=vectorizer.transform(test)\n",
    "test=tokenizer.texts_to_sequences(test)\n",
    "test=pad_sequences(test, maxlen=250, padding='post', truncating='post')\n",
    "pred1=model.predict(test, batch_size=300)\n",
    "pred2=model2.predict(test, batch_size=300)\n",
    "pred3=model3.predict(test, batch_size=300)\n",
    "pred4=model4.predict(test, batch_size=300)\n",
    "\n",
    "pred5=clf.predict(test)\n",
    "pred1=[pred1[i]*val_acc1*coef1 for i in range(len(pred1))]\n",
    "pred2=[pred2[i]*val_acc2*coef2 for i in range(len(pred2))]\n",
    "pred3=[pred3[i]*val_acc3*coef3 for i in range(len(pred3))]\n",
    "pred4=[pred4[i]*val_acc4*coef4 for i in range(len(pred4))]\n",
    "pred5=[pred5[i]*val_acc5*coef5 for i in range(len(pred5))]\n",
    "prediction=[(pred1[i]+pred2[i]+pred3[i]+pred4[i]+pred5[i])/(coef1*val_acc1+coef2*val_acc2+coef3*val_acc3+coef4*val_acc4+coef5*val_acc5) for i in range(len(pred1))]\n",
    "prediction = list(itertools.chain(*prediction))\n",
    "test_data['prediction']=prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000000</td>\n",
       "      <td>0.023338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7000001</td>\n",
       "      <td>0.018125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7000002</td>\n",
       "      <td>0.018746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7000003</td>\n",
       "      <td>0.021774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000004</td>\n",
       "      <td>0.414110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7000005</td>\n",
       "      <td>0.017248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7000006</td>\n",
       "      <td>0.017479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7000007</td>\n",
       "      <td>0.020903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7000008</td>\n",
       "      <td>0.022590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7000009</td>\n",
       "      <td>0.018754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7000010</td>\n",
       "      <td>0.018214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7000011</td>\n",
       "      <td>0.222771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7000012</td>\n",
       "      <td>0.019545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7000013</td>\n",
       "      <td>0.018273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7000014</td>\n",
       "      <td>0.018041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7000015</td>\n",
       "      <td>0.018160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7000016</td>\n",
       "      <td>0.117750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7000017</td>\n",
       "      <td>0.018460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7000018</td>\n",
       "      <td>0.059854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7000019</td>\n",
       "      <td>0.022666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7000020</td>\n",
       "      <td>0.020578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7000021</td>\n",
       "      <td>0.018129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7000022</td>\n",
       "      <td>0.017948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7000023</td>\n",
       "      <td>0.228896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7000024</td>\n",
       "      <td>0.573729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7000025</td>\n",
       "      <td>0.027922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7000026</td>\n",
       "      <td>0.053585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7000027</td>\n",
       "      <td>0.018598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7000028</td>\n",
       "      <td>0.016967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7000029</td>\n",
       "      <td>0.017808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  prediction\n",
       "0   7000000    0.023338\n",
       "1   7000001    0.018125\n",
       "2   7000002    0.018746\n",
       "3   7000003    0.021774\n",
       "4   7000004    0.414110\n",
       "5   7000005    0.017248\n",
       "6   7000006    0.017479\n",
       "7   7000007    0.020903\n",
       "8   7000008    0.022590\n",
       "9   7000009    0.018754\n",
       "10  7000010    0.018214\n",
       "11  7000011    0.222771\n",
       "12  7000012    0.019545\n",
       "13  7000013    0.018273\n",
       "14  7000014    0.018041\n",
       "15  7000015    0.018160\n",
       "16  7000016    0.117750\n",
       "17  7000017    0.018460\n",
       "18  7000018    0.059854\n",
       "19  7000019    0.022666\n",
       "20  7000020    0.020578\n",
       "21  7000021    0.018129\n",
       "22  7000022    0.017948\n",
       "23  7000023    0.228896\n",
       "24  7000024    0.573729\n",
       "25  7000025    0.027922\n",
       "26  7000026    0.053585\n",
       "27  7000027    0.018598\n",
       "28  7000028    0.016967\n",
       "29  7000029    0.017808"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "test_data=test_data.drop('comment_text', axis=1)\n",
    "test_data.head(30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000000</td>\n",
       "      <td>0.023338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7000001</td>\n",
       "      <td>0.018125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7000002</td>\n",
       "      <td>0.018746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7000003</td>\n",
       "      <td>0.021774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000004</td>\n",
       "      <td>0.414110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7000005</td>\n",
       "      <td>0.017248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7000006</td>\n",
       "      <td>0.017479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7000007</td>\n",
       "      <td>0.020903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7000008</td>\n",
       "      <td>0.022590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7000009</td>\n",
       "      <td>0.018754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7000010</td>\n",
       "      <td>0.018214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7000011</td>\n",
       "      <td>0.222771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7000012</td>\n",
       "      <td>0.019545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7000013</td>\n",
       "      <td>0.018273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7000014</td>\n",
       "      <td>0.018041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7000015</td>\n",
       "      <td>0.018160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7000016</td>\n",
       "      <td>0.117750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7000017</td>\n",
       "      <td>0.018460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7000018</td>\n",
       "      <td>0.059854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7000019</td>\n",
       "      <td>0.022666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7000020</td>\n",
       "      <td>0.020578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7000021</td>\n",
       "      <td>0.018129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7000022</td>\n",
       "      <td>0.017948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7000023</td>\n",
       "      <td>0.228896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7000024</td>\n",
       "      <td>0.573729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7000025</td>\n",
       "      <td>0.027922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7000026</td>\n",
       "      <td>0.053585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7000027</td>\n",
       "      <td>0.018598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7000028</td>\n",
       "      <td>0.016967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7000029</td>\n",
       "      <td>0.017808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  prediction\n",
       "0   7000000    0.023338\n",
       "1   7000001    0.018125\n",
       "2   7000002    0.018746\n",
       "3   7000003    0.021774\n",
       "4   7000004    0.414110\n",
       "5   7000005    0.017248\n",
       "6   7000006    0.017479\n",
       "7   7000007    0.020903\n",
       "8   7000008    0.022590\n",
       "9   7000009    0.018754\n",
       "10  7000010    0.018214\n",
       "11  7000011    0.222771\n",
       "12  7000012    0.019545\n",
       "13  7000013    0.018273\n",
       "14  7000014    0.018041\n",
       "15  7000015    0.018160\n",
       "16  7000016    0.117750\n",
       "17  7000017    0.018460\n",
       "18  7000018    0.059854\n",
       "19  7000019    0.022666\n",
       "20  7000020    0.020578\n",
       "21  7000021    0.018129\n",
       "22  7000022    0.017948\n",
       "23  7000023    0.228896\n",
       "24  7000024    0.573729\n",
       "25  7000025    0.027922\n",
       "26  7000026    0.053585\n",
       "27  7000027    0.018598\n",
       "28  7000028    0.016967\n",
       "29  7000029    0.017808"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
